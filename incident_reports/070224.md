# Incident Postmortem Report

## Basic Information
Date: 070223

Time: 0654

Duration:

## Initial Notes

0654: Opened app at 0654, server unreachable.
0655: Checked slack, produciton: exception groups.
0658: Loogin into render to check logs. "ninepanels.exceptions.BlacklistedAccessTokenException: problem reading blacklist table (psycopg2.OperationalError) connection to server at "db.ufwphjbjutqrirgceuor.supabase.co" (2a05:d014:1c06:5f02:2e2a:acd9:9376:c4cb), port 5432 failed: Network unreachable"
Looks like db error, related to deprecation of conneciton types?
0702: idenfited as issue with change conneciton strings. affecting prod and staging. testing envvar changes in staging
0707: identifed mismatches and changes, pushing new env var to staging.
0710 dpleoyed outage banner to prod after test in staging. gross looking needs work. spinners need work.


## Incident Summary
Incident Type: api server unreachable

Affected Services:  api server

User Impact: Users were unable to load panels, conduct any CRUD ops, login or conduct any actions that involved api calls.

## Root Cause Analysis

Preliminary Cause: See confirmed

Confirmed Cause: Render outage in Frankfurt Region

Contributing Factors: none

## Timeline of Events
14:00: app failing to fetch data: Noticed around 14:00 GMT+1 as I was coincidentally interacting with the app. No monitoring notificaiton were received until my interaction with the app generated clinet side rollbar errors indicating null responses from api calls.

14:05, user comms and db backup: Checking both Render and Supabase status pages confirmed Render had a major outage in the Frankfurt region. I quickly made a persistent message bar in front end and pushed that to prod. I took a data-only dump of the prod db using mc.sh

14:25, Resolution: from 14:20 GMT+1 Render emailed that incident had begun to be resolved. Testing of the app showed service resumed, removed banner at 14:25 GMT+1.

## Response and Mitigation
Immediate Actions Taken: Idenfitied source, notified users, took backup of db.

Long-term Mitigation Plans: service was restored, see action items, no ongoing effect.

## Lessons Learned
What Went Well: quick deployment of persistent user comms to client, ability to quickly backup prod db thanks to time investment in development of mc.sh

What Could Be Improved: alerting was not proactive, instead reactive on user input, no plans for backup or failover services in place. if outage had continued users just would not have been able to use the app.

Action Items:
 - monitoring of api server avilability must be integrated with rollbar and be proactive/automated:
   - alerts should not have relied on my interaction with the app.
   - api server health monitoring:
     - research and implement either direct rollbar render intgrations, user of webhooks, or a third party service that can intgerate with rollbar
   - database:
     - review supabase documentation to ascertain if their managed service includes failover provisions, and what requirement Nine Panels must have in place
     - if required implement further failover solutions
 - mitigation and failover plans.
   - api server:
     - set up multi region: second prod api server to be deployed in second render region, on free tier. Cold start of 30secs ok on free tier, as stays alive for ten minutes after last interaction. Future incidents will be monitored to see if upgrading backup server to paid instance during the incident is required. Envars will control which api server the front end communicates with.
     - regualr testing of failover in production
     - implementation:
       - immediate: setenvars on client to adapt and point to backup api server, manually set on vercel (client dpleoyment)
       - in current knwoeldge/skills: integrate to mc.sh to set FE envars using vercel api (requires FE side mc.sh to be built)
       - further learning required: cron jobs/scripts/automation to automatially detect failed primary server and flip envars to gets client to point to backup.

 - client:
   - further work to identify and enumerate different api call errors and communicate effectively to users and into rollbar. currently if api calls receive an error respons, these are parsed into temporary banners, but network/sever unreachable errors have not be enumerated and instead have a catch all error banner.
   -  rollbar logging on clinet must be more tighly intgrated with try catch error blocks

Action plan:

Above items to be integrated into upcoming refactor after v0.1 release. Update on progress will be added below

Action / Implementation updates:

070923 - postmortem
070923 - connected render and vercel to slack for future service related notifications, built a free statuspage